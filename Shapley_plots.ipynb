{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "from inception_v3_archisen import InceptionV3  #this inputes are uint8 to check for shalpley problems\n",
    "import keras\n",
    "from skimage.segmentation import slic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "Input_model = Input((299,299,3))  #299 can be anynumber or even None if undefined\n",
    "Incept_model = InceptionV3(include_top=False, #chop of top\n",
    "                weights='imagenet', #get pretrained weights\n",
    "                input_tensor=Input_model, #trying uint8 image format\n",
    "                input_shape=(299,299,3), #ignore\n",
    "                pooling=None, #ignore\n",
    "                classes=1000) # classes: optional number only if top is true\n",
    "\n",
    "output = Incept_model.output\n",
    "output # shape of tensor is  (batch_size, Length,Width, Channels) \n",
    "output2 = keras.layers.GlobalAveragePooling2D()(output) \n",
    "output2 #global max pooling finds the max point in each channel. Frequently used, max finds the strongest signal. Average is also reasonable\n",
    "output2 = keras.layers.Dropout(0.5)(output2)\n",
    "output3 = keras.layers.Dense(96,activation='relu') (output2) # dense neural network with 50 layers\n",
    "output4 = keras.layers.Dense(4, activation=\"softmax\") (output3) # output 3 classes in probabiltites with softmax\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Lambda\n",
    "model = Model(Input_model,output4) #using logits layer\n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "                    optimizer = 'adam',#ptimizers.SGD(lr=0.1),\n",
    "                    metrics=['categorical_crossentropy',\"accuracy\"])\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "model_path = 'transfer_model.h5'\n",
    "callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_categorical_crossentropy', \n",
    "            patience=3, # stop training at 3\n",
    "            verbose=0),\n",
    "        \n",
    "        ModelCheckpoint(\n",
    "            model_path , \n",
    "            monitor='val_categorical_crossentropy', \n",
    "            save_best_only=True, \n",
    "            verbose=0)\n",
    "    ]\n",
    "batch_size =32\n",
    "from keras.callbacks import TensorBoard\n",
    "tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1,\n",
    "                         write_graph=True,\n",
    "                         write_grads=True,\n",
    "                         batch_size=batch_size,\n",
    "                         write_images=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "skip = 2 #increase this to reduce sample size if low memory\n",
    "c0 = np.load(gzip.GzipFile('./train/c_30.npy.gz'))[::skip] # tomato late blight\n",
    "c1 = np.load(gzip.GzipFile('./train/c_31.npy.gz'))[::skip] # Tomato leaf mold \n",
    "c2 = np.load(gzip.GzipFile('./train/c_32.npy.gz'))[::skip] # Septrio leaf spot\n",
    "c3 = np.load(gzip.GzipFile('./train/c_37.npy.gz'))[::skip] # healthy\n",
    "y0 = np.array([[1,0,0,0],]*c0.shape[0]) #one hot encoded labels\n",
    "y1 = np.array([[0,1,0,0],]*c1.shape[0])\n",
    "y2 = np.array([[0,0,1,0],]*c2.shape[0])\n",
    "y3 = np.array([[0,0,0,1],]*c3.shape[0])\n",
    "\n",
    "# concateneate all classes together\n",
    "X ,y = np.concatenate([c0,c1,c2,c3],axis=0), np.concatenate([y0,y1,y2,y3],axis=0)\n",
    "del c0,c1,c2,c3\n",
    "del y0,y1,y2,y3 #clear RAM\n",
    "\n",
    "X_tr ,y_tr = X[0::2,], y[0::2,]\n",
    "X_val , y_val = X[1::2,],y[1::2,]\n",
    "del X ,y\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('transfer_model.h5') #trained with astar super computer for 30mins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dictt= np.load('dictt_BetterSampling_100.npy').item()\n",
    "print len(dictt)\n",
    "print len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in dictt.keys():\n",
    "    assert np.mean(dictt[i][0]==X_val[i])==1\n",
    "print 'Pictures tally'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_names={0:'late blight',1:'leaf mold',2:'leaf spot',3:'healthy'}\n",
    "from matplotlib import cm\n",
    "for i in sorted(dictt.keys())[::]:\n",
    "    img = dictt[i][0]\n",
    "    phi = dictt[i][1]\n",
    "    actual_class = class_names[np.argmax(y_val[i])]\n",
    "    preds = map(lambda x : np.round(x,2),model.predict(np.array([img]))[0])\n",
    "    if max(preds) > 0.9:\n",
    "        if actual_class != class_names[np.argmax(preds)]:\n",
    "            print 'THE FOLLOWING WAS PREDICTED WRONGLY'\n",
    "        max_val = max(np.abs(np.concatenate(phi)))\n",
    "        segments_slic = dictt[i][2]\n",
    "        new_image = np.zeros((299,299))\n",
    "        f,ax = plt.subplots(1,4,figsize=(12*2,2*4.2))\n",
    "        counter  = 3\n",
    "        for ii in np.argsort(preds)[::]:\n",
    "          for i in range(299):\n",
    "            for j in range(299):\n",
    "              new_image[i,j] = phi[ii][segments_slic[i,j]]\n",
    "          if class_names[ii] == actual_class:\n",
    "              ax[counter].set_title('TRUE LABEL\\n'+class_names[ii]+'\\n'+str(preds[ii])[:4]   )\n",
    "          else:\n",
    "              ax[counter].set_title(class_names[ii]+'\\n'+str(preds[ii])[:4]   )\n",
    "          cax = ax[ii].imshow( (np.mean(img,-1) > 0.1)*1*new_image, \n",
    "                                   vmin=-max_val, vmax=max_val,cmap = plt.cm.bwr)\n",
    "          counter += -1\n",
    "        cb = plt.colorbar(cax,  ax=ax.ravel().tolist(), label=\"SHAP value\", orientation=\"horizontal\", aspect=60)\n",
    "        #cbar = plt.colorbar(cax,ticks=[-1.5,-1,-0.75,-0.5,-0.25, 0,.25,.5, 75, 1,1.5], orientation='horizontal')\n",
    "        plt.show()\n",
    "        f,ax = plt.subplots(1,3,figsize=(12*2,2*2.5))\n",
    "        ax[0].imshow(img)\n",
    "        lower_bd = np.percentile(np.concatenate(new_image),20)\n",
    "        upper_bd = np.percentile(np.concatenate(new_image),80)\n",
    "        new_image= np.stack([new_image]*3,-1)\n",
    "        ax[1].imshow(img*(new_image > upper_bd))\n",
    "        ax[1].set_title('pos shap values')\n",
    "        ax[2].imshow(img*(new_image < lower_bd))\n",
    "        ax[2].set_title('neg shap values')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_names={0:'late blight',1:'leaf mold',2:'leaf spot',3:'healthy'}\n",
    "from matplotlib import cm\n",
    "for i in sorted(dictt.keys())[::]:\n",
    "    img = dictt[i][0]\n",
    "    phi = dictt[i][1]\n",
    "    actual_class = class_names[np.argmax(y_val[i])]\n",
    "    preds = model.predict(np.array([img]))[0]\n",
    "    if max(preds) < 0.9:\n",
    "        if actual_class != class_names[np.argmax(preds)]:\n",
    "            print 'THE FOLLOWING WAS PREDICTED WRONGLY'\n",
    "        max_val = max(np.abs(np.concatenate(phi)))\n",
    "        segments_slic = dictt[i][2]\n",
    "        new_image = np.zeros((299,299))\n",
    "        f,ax = plt.subplots(1,4,figsize=(12*2,2*4.2))\n",
    "        counter  = 3\n",
    "        for ii in np.argsort(preds)[::]:\n",
    "          for i in range(299):\n",
    "            for j in range(299):\n",
    "              new_image[i,j] = phi[ii][segments_slic[i,j]]\n",
    "          if class_names[ii] == actual_class:\n",
    "              ax[counter].set_title('TRUE LABEL\\n'+class_names[ii]+'\\n'+str(preds[ii])[:4]   )\n",
    "          else:\n",
    "              ax[counter].set_title(class_names[ii]+'\\n'+str(preds[ii])[:4]   )\n",
    "          cax = ax[counter].imshow( (np.mean(img,-1) > 0.1)*1*new_image, \n",
    "                                   vmin=-max_val, vmax=max_val,cmap = plt.cm.bwr)\n",
    "          counter += -1\n",
    "        cb = plt.colorbar(cax,  ax=ax.ravel().tolist(), label=\"SHAP value\", orientation=\"horizontal\", aspect=60)\n",
    "        #cbar = plt.colorbar(cax,ticks=[-1.5,-1,-0.75,-0.5,-0.25, 0,.25,.5, 75, 1,1.5], orientation='horizontal')\n",
    "        plt.show()\n",
    "        f,ax = plt.subplots(1,3,figsize=(12*2,2*2.5))\n",
    "        ax[0].imshow(img)\n",
    "        lower_bd = np.percentile(np.concatenate(new_image),20)\n",
    "        upper_bd = np.percentile(np.concatenate(new_image),80)\n",
    "        new_image= np.stack([new_image]*3,-1)\n",
    "        ax[1].imshow(img*(new_image > upper_bd))\n",
    "        ax[1].set_title('pos shap values')\n",
    "        ax[2].imshow(img*(new_image < lower_bd))\n",
    "        ax[2].set_title('neg shap values')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Hi Sam and Martin,\n",
    "\n",
    "I would like to suggest myself for the tensorflow meetup talk after playing quite abit around shapley values from Scott M. Lundberg NIPS 2016 paper titled \"A Unified Approach to Interpreting Model Predictions\"\n",
    "\n",
    " :  Explainable AI : Using Shapley values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
